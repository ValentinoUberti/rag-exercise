quarkus.langchain4j.chat-model.provider=ollama
quarkus.langchain4j.ol.chat-model.provider=ollama
#quarkus.langchain4j.ollama.ol.chat-model.model-id=fLlama-2-7b
quarkus.langchain4j.ollama.ol.chat-model.model-id=llama2
quarkus.langchain4j.ollama.ol.chat-model.num-predict=500


quarkus.langchain4j.ollama.ol.log-requests=true
quarkus.langchain4j.ollama.ol.log-responses=true
quarkus.langchain4j.ollama.ol.timeout=600s

# quarkus.langchain4j.oai.chat-model.provider=openai
# quarkus.langchain4j.openai.oai.base-url=http://localhost:11434/v1
# quarkus.langchain4j.openai.oai.api-key=xxx
# quarkus.langchain4j.openai.oai.chat-model.model-name=fLlama-2-7b
# quarkus.langchain4j.openai.oai.timeout=60

# quarkus.langchain4j.openai.oai.chat-model.log-requests=true
# quarkus.langchain4j.openai.oai.chat-model.log-responses=true

# quarkus.langchain4j.chat-model.provider=openai
# quarkus.langchain4j.openai.api-key=xxx
# quarkus.langchain4j.openai.base-url=http://localhost:11434/v1
# quarkus.langchain4j.openai.chat-model.model-name=fLlama-2-7b
# quarkus.langchain4j.openai.timeout=60
# quarkus.langchain4j.openai.chat-model.log-requests=true
# quarkus.langchain4j.openai.chat-model.log-responses=true


quarkus.langchain4j.embedding-model.provider=ollama
quarkus.langchain4j.redis.dimension=384
quarkus.redis.max-pool-waiting=10000
quarkus.redis.devservices.image-name=redis/redis-stack:latest

quarkus.otel.traces.exporter=none